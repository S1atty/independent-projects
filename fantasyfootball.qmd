---
title: "Singular Value Decomposition - Enhanced Principal Components to Optimize Fantasy Football Teams"
author: "Tomi Akisanya"
format: 
  html:
    toc: true               # Enable table of contents
    toc-depth: 10
    toc-expand: 20            # Set depth of headers to include in TOC
    toc-location: right      # Location of the TOC (optional)
    number-sections: false   # Enable section numbering (optional)
editor_options: 
  settings:
    chunk_output_type: console
    canonical: TRUE
---
```{r setup,eval = TRUE, echo = FALSE, include=FALSE, warning=FALSE, error=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE, cache=FALSE, warning = FALSE,message= FALSE)
```


```{r, eval = TRUE, echo = FALSE, include = FALSE, warning=FALSE}
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(magrittr)
library(rvest)
library(openxlsx)
library(car)
library(psych)
library(corrplot)
library(DT)
library(reshape2)
library(knitr)
# install.packages(c("corrr","ggcorrplot","FactoMineR"))
library(corrr,ggcorrplot)
# install.packages("factoextra")
library(factoextra) # pca visualization
# library(gt) # 'beautiful tables'
library(stringr)
library(forcats)

# title: "Singular Value Decomposition - Enhanced Principal Components to Optimize Fantasy Football Teams"
# author: "Tomi Akisanya"
# output: html_document
# editor_options: 
#   settings:
#   chunk_output_type: console
#   canonical: TRUE

```

Around this time every year, if you're like me, you've already started to mentally prepare for 80% of your conversations to be on the topic of football. For those individuals that would not classify themselves as ffanatics, it's probably annoying - *it's annoying for all of us*. Pretty consistently there will behavior from fans that range from DMs to athletes, verbal assaults to close friends, damaged property, and public humiliation. Who realistically has the mental endurance to only discuss a single topic over an extended period of time for something they're not physically involved in? It's those with passion, and although I am not passionate about football (nor justify the aforementioned behavior), it will be my first of hopefully many Fantasy Football leagues. If there's one thing I am passionate about, it's tilting the odds in my favor. Usually that's in the form of taking a creative line on the felt on a 2/5 reg by extracting max value with 67s on a low connected board in a 4! pot as the preflop aggressor. Balance and discipline is the name of the game though, and who are we if we don't apply the same approach to all areas in life...


# Data Sets

The data contains in-game and Fantasy Football Points per Reception stats by NFL player from 2017 - 2023 for all 17 games of the regular season. Most leagues use a points per reception based metric to calculate fantasy points, or `FantasyPointsPPR.` Before converting to fantasy points, in-game stats may be weighted or counted differently. My league adopted the following criterion: 

```{r}
league_weights <- data.frame(read.xlsx("Fantasy Football Data/archive/fantasy_strata_league_scoring.xlsx"))
knitr::kable(league_weights[,-3])
```

Two different data sets are used, with a focus on three distinct NFL regular seasons - 2022, 2023, and 2024. Both data sets have been scraped but differ in source, purpose, and underlying information present:

Data Set 1 - Historical - 2022 & 2023: This data set contains historical data from 2017-2023 for both relevant in-game statistics and fantasy scoring for  regular NFL season. This project primarily focuses on 2022 and 2023. Each observation or row in the data set is a NFL athlete's relevant in-game statistics, such as position, team, completion, attempts, interceptions per attempt, etc. Since most leagues exclude defensive players from their fantasy team, those have been implicitly removed from the data set. The key feature of this data set are the retroactive fantasy rankings/scoring. The total fantasy points, overall rank, and rank by position are available for each player. This enables the direct comparison of calculated rankings from models to their actual rank.

Players that were on two or more teams in a given season are not assigned a team - but are instead given a makeshift name to highlight this. For example, you may see Baker Mayfield's registered team as `2TM.` One notable variable contained in the data set is ADP, or average draft position, representing the number of times the player was drafted across all recorded leagues before the start of the respective season. Additional in-game stats were calculated afterwards. These were `YardsPerRushAttempt`,`CompletionsPerAttempt`, `TDsPerAttempt`, `InterceptionsPerAttempt`, `TDsPerReception`, and `FumblesLostPerFumble.` My fantasy league's scoring methodologies were also factored into a set of new variables. These variables have the `schoring_` schema. 

Years 2017-2022 and 2023 are taken from the same source but were scraped separately. Player IDs assigned 

Data Set 2 - Projected - 2024: This data set contains all player match ups for the upcoming regular 2024 NFL season. The in-game statistics recorded for each player are projections based on those teams and match ups. One benefit of this data set is being able to use these projections as inputs of our model to determine which players obtain the most fantasy points, rank them in ascending order, and draft them accordingly. The drawback is that no additional information on how these projections were calculated are known so the accuracy of these projections cannot be confirmed. 

# Methods

The current methodology is to use singular value decomposition of eigenvalues to create scores of new variables that can be attributed to their overall performance. Their projected overall performance would be used to rank each player in ascending order (potentially by position) to inform our draft decision. Starting with the 2022 season, the overall rank for each player is calculated and then compared to the actual ranks of that same year. Precision will be measured in three ways: 

1. Difference in overall rank
2. Difference in position rank
3. Difference in fantasy points, obtained by taking the difference of fantasy points using our model's draft order with the fantasy points using the ideal draft order.

If the model is precise, the same 2022 projections will then be tested on 2023. This method is not full-proof obviously. Many things change between off seasons of professional sports, but the objective is to quantify the model's ability to generalize onto future seasons. If it can, the same process will be done starting with the 2023 data set, testing it against itself, then using those scores for 2024. If it does not, principal component scores will be calculated using the 2024 data set only, and only those will inform our draft order. This is not the ideal scenario, since it inherently trusts the projected data. 

```{r, eval = TRUE, echo = FALSE, include=FALSE}

fantasy_merged_17_22 <- read_csv("Fantasy Football Data/archive/fantasy_merged_7_17.csv")
fantasy_adp_17_22 <- read_csv("Fantasy Football Data/archive/adp_merged_7_17.csv")
fantasy_adp_17_22 <- data.frame(fantasy_adp_17_22)
mydata_id <- read_csv("Fantasy Football Data/archive/adp_merged_7_17.csv")
# fantasy_test_23 <- read.xlsx("fantasy_mergedsourcecleaned_2023.xlsx") 2023 test

mydata <- fantasy_merged_17_22 %>%
  left_join(fantasy_adp_17_22 %>%
              select(PlayerID,adp,Year), by = c("PlayerID","Year")) %>%
  data.frame()

fantasy <- mydata %>%
  rename(
    Rank = Rk,
    Player = Player,
    Team = Tm,
    FantasyPosition = FantPos,
    Age = Age,
    Games = G,
    GamesStarted = GS,
    Completions = Cmp, #QB
    Attempts = Att, #QB
    PassingYards = Yds, # SCORING: (*1/25)
    PassingTDs = TD, # SCORING: (*4)
    Interceptions = Int, # SCORING: (*-2)
    RushingAttempts = RushAtt,
    RushingYards = RushYds,  # SCORING: (*1/10)
    YardsPerAttempt = YA, # ***RushingYards / RushingAttempts 
    RushingTDs = RushTD, # SCORING(*6)
    Targets = Tgt, # TE/WR no. times player is thrown ball 
    Receptions = Rec, # no. passes caught; SCORING: (*1)
    ReceivingYards = RecYds, # SCORING: (*.1)
    YardsPerReception = YR, # ***ReceivingYards / Receptions ; compelte rate = .85
    ReceivingTDs = RecTD, # SCORING: (*6)
    Fumbles = Fmb, # SCORING: (*-2)
    FumblesLost = FL, # no times player fumbles and opp team receives; SCORING: (*-2)
    FantasyPointsPPR = PPR, # no fantasy pts in a points per reception league
    PlayerID = PlayerID,
    PositionRank = PosRk, # ranking grouped by position
    Year = Year, 
    ADP = adp
  )

fantasy %<>% mutate(
  YardsPerRushAttempt = RushingYards / RushingAttempts, # duplicate 
  CompletionsPerAttempt = Completions / Attempts,
  TDsPerAttempt = PassingTDs / Attempts,
  InterceptionsPerAttempt = Interceptions / Attempts,
  TDsPerReception = ReceivingTDs / Receptions, # complete r = .85
  FumblesLostPerFumble = FumblesLost / Fumbles, .after = ADP # complete rate = .4
)

fantasy %<>% mutate(Team = factor(Team), FantasyPosition = factor(FantasyPosition))

# including scoring 

fantasy %<>% mutate(
  scoring_PassingYards = PassingYards*.04,
  scoring_PassingTDs = PassingTDs*4,
  scoring_Interceptions = Interceptions*(-2),
  scoring_RushingYards = RushingYards*(.01),
  scoring_RushingTDs = RushingTDs*6,
  scoring_Receptions = Receptions*1,
  scoring_ReceivingYards = ReceivingYards*.1,
  scoring_ReceivingTDs = ReceivingTDs*6,
  scoring_Fumbles = Fumbles*(-2),
  scoring_FumblesLost = FumblesLost*(-2)
)


```

# Processing 

Missing values in completions per attempt, tds per attempt, interceptions per attempt, tds per reception, and fumbles lost per fumble were a result of undefined values in the denominator. Observations of this missing values are directly related to the player and position. For example, QBs will rarely record touchdowns per reception and will therefore have undefined values for those statistics since they are more equipped to measure performance of wide receivers. All missing values in these cases were replaced with zero. The same approach was applied to yards per attempt and yards per reception with two notable exceptions. Foster Moreau had zero rushing attempts but two rushing yards during the 2022 NFL season which is difficult to interpret considering rushing attempts are a function of rushing yards. In the same vein, Joe Flacco had -3 receiving yards but zero receptions. Both of these players were removed from the data set. 

```{r, eval=FALSE}


fantasy %>%
  select(-ADP,-YardsPerAttempt) %>%
  filter(if_any(everything(),is.na)) %>%
  tibble() 

# YardsPerAttempt - RushingYards / RushingAttempt

fantasy %>%
  filter(!is.na(YardsPerAttempt) & RushingYards!=0) %>%
  slice_sample(n=5) %>%
  summarize(n=RushingYards,n2=RushingAttempts,n3=YardsPerAttempt,n4=RushingYards/RushingAttempts) # data quality check
fantasy %>%
  filter(is.na(YardsPerAttempt),
         (RushingYards!=0 & RushingAttempts==0)|(RushingYards==0 & RushingAttempts!=0)) %>%
  select(Player,PlayerID)
# Foster Moreau MoreFo00 has 0 rushing attempts but 2 rushing yards. Will most likely remove player from data set. 
# all other players are na(YardsPerAttempt) since RushingYards = 0 and RushingAttempts = 0

# YardsPerReception - ReceivingYards / Receptions
fantasy %>% filter(is.na(YardsPerReception)) 
fantasy %>%
  filter(!is.na(YardsPerReception) & Receptions!=0) %>%
  slice_sample(n=5) %>%
  summarize(n=Receptions,n2=ReceivingYards,n3=YardsPerReception,n4=ReceivingYards/Receptions)
fantasy %>%
  filter(is.na(YardsPerReception),
         (ReceivingYards!=0 & Receptions==0)|(ReceivingYards==0 & Receptions!=0)) %>%
  select(Player,PlayerID)
# Joe Flacco FlacJo00 - -3 receiving yards but 0 receptions; doesn't make sense depends on how its counted

# CompletionsPerAttempt
fantasy %>% filter(is.na(CompletionsPerAttempt))
fantasy %>%
  filter(!is.na(CompletionsPerAttempt) & Attempts!=0) %>%
  slice_sample(n=5) %>%
  summarize(n=Completions,n2=Attempts,n3=CompletionsPerAttempt,n4=Completions/Attempts)
fantasy %>%
  filter(is.na(CompletionsPerAttempt),
         (Completions!=0 & Attempts==0)|(Completions==0 & Attempts!=0)) %>%
  select(Player,PlayerID) # no results; substitute zero for NaN

# TDsPerAttempt
fantasy %>%
  filter(is.na(TDsPerAttempt),
         (PassingTDs!=0 & Attempts==0)|(PassingTDs==0 & Attempts!=0)) 

# InterceptionsPerAttempt
fantasy %>%
  filter(is.na(InterceptionsPerAttempt),
         (Interceptions!=0 & Attempts==0)|(Interceptions==0 & Attempts!=0)) 

# TDsPerReception
fantasy %>%
  filter(is.na(TDsPerReception),
         (ReceivingTDs!=0 & Attempts==0)|(ReceivingTDs==0 & Attempts!=0))

# FumblesLostPerFumble
fantasy %>%
  filter(is.na(FumblesLostPerFumble),
         (FumblesLost!=0 & Fumbles==0)|(FumblesLost==0 & Fumbles!=0)) 

```


```{r}

# remove joe flacco and foster moreau
fantasy <- fantasy[!fantasy$PlayerID %in% c("FlacJo00","MoreFo00"),]

# remove duplicate variable YardsPerRushAttempt
fantasy %<>% select(-YardsPerRushAttempt)
# replace NaN with 0 
sum(is.na(fantasy$YardsPerAttempt))

for (i in seq_along(1:nrow(fantasy))){
  for (j in seq_along(1:ncol(fantasy))){
    if (any(is.na(fantasy[i,j])) & j != 28){
      fantasy[i,j] <- 0
    }
  }
}

```

# YoY PPR Trend for Top NFL Teams

```{r, eval = TRUE, echo = FALSE, fig.width=15,fig.height=10}


fantasy %>%
  select(Year,Team,FantasyPointsPPR) %>%
  group_by(Year,Team) %>%
  summarize(n=sum(FantasyPointsPPR)) %>%
  slice_max(n, n = 5) %>%  # PHI, KAN, MIN, JAX, CIN
  ggplot(aes(x = n, y = factor(Year), fill=Team, label = Team, color = Team)) +
  geom_col(position = "dodge", show.legend = FALSE) +  
  coord_cartesian(xlim=c(1300,1900))+
  scale_fill_manual(values=c("KAN"="red4"))+
  scale_color_manual(values=c("KAN"="red4"))+
  geom_text(position = position_dodge(width = 0.9), hjust = -0.1, show.legend = FALSE) + 
  labs(x = "Fantasy Points PPR", y = "Year", title = "Fantasy Points by Team and Year") +
  theme_minimal() +  # Optional: Apply a minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(color = "red4")) 

```

# 2022 NFL season\n


## Data Exploration\n


The data was sub set for the 2022 season and then skimmed for to review distributions, counts, and other elements within the data set. 

```{r}

fantasy <- fantasy %>%
  filter(Year == 2022)
skimr::skim(fantasy)
```

Important categorical variables to note outside of the Team and Player is the Fantasy Position. These are QBs, WRs, TEs, and RBs. All defensive positions are not scoped and have been explicitly removed from the data set. The objective of this project is to create a fantasy team that has the highest likelihood of obtaining the most Fantasy Points (PPR) for the upcoming season based on prior seasons. The next logical question becomes, does this likelihood vary by team? By position? Intuitively, the likelihood will vary simply based on how many of these positions are in game at a given time. A table of each position shows the distribution of each position in a given NFL season.  

```{r}
fantasy %>%
  janitor::tabyl(FantasyPosition) %>%
  arrange(desc(percent))
```

A majority of NFL players in 2022 for fantasy purposes were wide receivers (38%) while the least common position were quarterbacks (14%). For the continuous variables, the important things to note are the means, standard deviations, their counts and distribution via the histograms, and any missing values. In-game stats such as Yards Per Attmept, Yards per Reception, and additional variables (below ADP) are missing for a lot of players as expected. The missing values are likely due to a number of factors such as the position of the player and the number of games each played. The range of games played by each player vary from none to 17, representative of 17 total games in the regular season. The descriptive summary for Fantasy Points (PPR) is: 

```{r}
psych::describe(fantasy$FantasyPointsPPR)
```

With mean = 78.4 (sd = 85.29), it is obvious that there is high variability. The histogram of PPR shows where how this variability is distributed. 

```{r}
hist(fantasy$FantasyPointsPPR, main = "Histogram of Fantasy Points (PPR)",
     xlab = "PPR", ylab = "Count")
```

Depending on the fantasy league, PPR scoring will be different in the sense that there is typically a PPR threshold per game for a player in order for their PPR to be recorded for that given week. If the player is below the baseline, the PPR may be zero. Interestingly enough, the distribution of PPR in 2022 is a log-normal right skew distribution. The observed PPR for most players were approximately zero. This is logical, granted the extreme difficulty of being a top NFL performer. Most players are benched, aren't playing games, nor are starters. Evidently, most of the continuous variables will follow the same trend with observed frequencies ~0 and relatively a fewer number of players scoring the most for each variable. There are three notable exceptions: 

```{r,fig.align='center'}

h_adp1 <- 
fantasy %>%
  ggplot(aes(x=ADP))+
  geom_histogram(bins = 8, color = "black")+
  scale_x_continuous(name = "ADP")+
  scale_y_continuous(name = "Count")+
  labs(title = "Average Draft Position")
  
h_adp2 <- 
fantasy %>%
  ggplot(aes(x=FumblesLostPerFumble))+
  geom_histogram(bins = 9, color = "black")+
  scale_x_continuous()+
  labs(title = "Fumbles Lost per Fumble")+
  theme(axis.title.y = element_blank())
h_adp3 <-  
  fantasy %>%
  ggplot(aes(x=YardsPerReception))+
  geom_histogram(bins = 11, color = "black")+
  labs(title =  "Yards Per Reception")+
  theme(axis.title.y = element_blank())

gridExtra::grid.arrange(h_adp1,h_adp2,h_adp3, ncol = 3)

```

1. Average Draft Position - Uniform Distribution: For players that have this data available, ADP is uniformly distributed across most players. This implies that the parent population drafts players evenly across the board and there isn't a strong concentration of players being picked predominantly. To reiterate, this is specifically for players that have ADP data available, which may be a combination of the most popular or the best players. 

2. Fumbles Lost per Fumble - Bimodal distribution: Frequency of Fumbles Lost per Fumble have peaks at both zero and one, revealing that most players either fumble and lose possession of the ball, resulting in a turnover, or don't fumble at all. 

3. Yards Per Reception - Normal distribution: Players average 10 Yards Per Reception with a majority of players within the range of two standard deviations from the mean. Although there is a slight right skew, this is one of the few variables that follows a Gaussian distribution. 

The first thing we want to understand is *what* position, if any, we should be more inclined to draft first, and their likelihood of obtaining the most fantasy points. I started by seeing what the public likes to draft first. In 2022, the public drafted quarterbacks around 86 times on average, the highest of the four positions, with tight ends at a close second of 84 times on average. Running backs and wide receivers then followed. Acknowledging that ADP data is not available for all positions, I wanted to better understand if quarterbacks are the biggest factor in regards to PPR. A comparison of ADP and PPR by position begins to paint the picture. On average, quarterbacks had 105 fantasy points in 22, followed by wide receivers, running backs, then tight ends.

```{r}

fantasy %>%
  select(FantasyPosition,FantasyPointsPPR,ADP) %>%
  group_by(FantasyPosition) %>%
  summarize(AverageDraftPosition=mean(ADP, na.rm=TRUE),
            AveragePPR=mean(FantasyPointsPPR, na.rm=TRUE)) %>%
  arrange(desc(AveragePPR)) 
# QB / WR / RB / TE -- avg PPR
# wr / rb / qb / te -- total (totals are void see below)

```

This seems to be consistent at a higher level when the top three teams for the 2022 regular season are compared. 

```{r, eval = TRUE, echo = FALSE, fig.width=15,fig.height=10}
fantasy %>%
  filter(Team %in% c("PHI","KAN","CIN")) %>%
  select(Team,FantasyPosition,FantasyPointsPPR) %>%
  group_by(Team,FantasyPosition) %>%
  summarize(n=mean(FantasyPointsPPR),
            n2=sum(FantasyPointsPPR)) %>%
  slice_max(n, n = 5) %>%
  arrange(desc(n)) %>%
  ggplot(aes(y=fct_rev(fct_inorder(FantasyPosition)),x=n,fill=Team,color=Team, label = Team)) +
  geom_col(position = "dodge") +  
  scale_fill_manual(values=c("KAN"="red4","PHI"="palegreen4","CIN"="slategray4"))+
  scale_color_manual(values=c("KAN"="red4","PHI"="palegreen4","CIN"="slategray4"))+
  # coord_cartesian(xlim=c(1250,2000))+
  geom_text(position = position_dodge(width = 0.9), hjust = -0.1) +  # Add text labels
  labs(x = "Fantasy Points PPR", y = "Year", title = "Fantasy Points by Team and Year") +
  theme_minimal() +  # Optional: Apply a minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size=12),
        axis.text.y = element_text(size=12),
        legend.position = "top") 
```


However, properly accounting for total number of games played by player, yields different results. Evidently, quarterbacks are disproportionately the most efficient in regard to fantasy points on a per game basis at .164 per game. Running backs, tight ends, and receivers consecutively follow but are significantly behind. However, fantasy points between those three positions vary by less than 5%.  The logical question becomes what are the underlying causes of this variation? One possibility is that there are typically more wide receivers on an offensive play than any other position. Another possibility can be due to the extreme routes and distances wide receivers run, making them injury prone and therefore less efficient. 

```{r}

fantasy %>%
  group_by(FantasyPosition) %>%
  summarize(PPRperGame = mean(FantasyPointsPPR,na.rm = TRUE)/sum(Games,na.rm=TRUE)) %>%
  arrange(desc(PPRperGame)) # PPR efficiency (after accounting for # of games played)
# QBs have most efficient PPR on per game basis, WRs seem to have the lowest impact on per game basis
# After accounting for no. of games, QB > RB > TE > WR  

```

## Analysis SVD PCA 

Eigenvalue decomposition is an unsupervised machine learning method typically used for dimensionality reduction on mostly unlabeled data. The same approach is used here, with the intent to reduce the data to components that measure performance in some aspect. The best way to think about this is in the form of a recipe. A cookbook's recipe for chicken cordon bleu will have elaborate concoctions and mixes of different food. When applied in this context, it would reduce the recipe to its core components, 3/4 chicken, 1/8 cheese, 1/8 ham let's say. It then becomes much easier to make chicken cordon bleu while keeping most of the taste. While an oversimplification, the approach is essentially the same, with the goal of maximizing the amount of underlying variation using linear combinations of variables. At its core, there is some latent underlying variable(s) that combinations of these variables measure. What those underlying variables measure and its relevancy is on us to define. These are the principal components. The principal components are made up of the original variables, and how much that variable contributes to the underlying variable (ie principal component) are the eigen vectors or *loadings*. Loadings can be positive (greatly contributes) or negative (adversely contributes). How well the variables load help define what that new underlying variable is. To define the inclusion criteria, any variable that loads +/- .7 will be considered as loading well and those variables alone will be what is used to define the underlying variable/component. This empirical threshold is a very conservative approach. 

```{r}

## 1) Scale, remove ADP, Year, Rank, PositionRank, (maybe Games and Age); 2) create correlation matrices

# og x_vars
ffnorm_og <- fantasy %>%
  select(where(is.numeric) & -ADP & -Year & -FantasyPointsPPR & -Rank & -PositionRank &
         !contains("scor", ignore.case = TRUE)) %>%
  mutate_all(scale.default)
# -- og cor matrix
fantasy_cormatrix_og <- 
  fantasy %>%
  select(where(is.numeric) & -ADP & -Year & -FantasyPointsPPR & -Rank & -PositionRank &
         !contains("scor", ignore.case = TRUE)) %>%
  cor()

# all x_vars
ffnorm_all <- fantasy %>%
  select(where(is.numeric),-ADP,-Year,-FantasyPointsPPR,-Rank, -PositionRank) %>%
  mutate_all(scale.default)
# -- all cor matrix
fantasy_cormatrix_all <- fantasy %>%
  select(where(is.numeric),-ADP,-Year,-FantasyPointsPPR,-Rank, -PositionRank) %>%
  cor()

# scoring vars
ffnorm_score <- fantasy %>%
  select(contains("scor", ignore.case = TRUE)) %>%
  mutate_all(scale.default)
# -- scoring cor matrix
fantasy_cormatrix_scoring <- fantasy %>%
  select(contains("scor", ignore.case = TRUE)) %>%
  cor()

```

Eigen vectors describe a mathematical phenomena such that 

$$ A * v =  λ * v $$

where A is a square matrix, v is an eigen vector, and λ is a scalar (numerical value) and the associated eigen value of vector v. In this application, matrix A is correlation matrix of the original data. This mechanism works because linear transformations are applied to the data meaning the data does not inherently change. The proportions of all variables and the direction in which they move remain the same. The data gets centered at the origin after scaling, and a best fitting line is calculated that goes through the origin and maximizes the variance in the data. The algorithm does this by fitting a random line through the data, projecting the points onto the line, and calculating the largest sum of squared difference. The yielded line of best fit is the eigen vector for the principal component and the slope is the eigen value. 

```{r,fig.align='center',fig.width=8,fig.height=6}

#scree_plot1 <- fa.parallel(fantasy_cormatrix_og,n.iter=100,fa="pc", main="Parallel Scree")
# parallel test suggests pc1-pc3 on conservative side; scree test suggest up to pc5
# psych::scree(fantasy_cormatrix_og,pc=TRUE,factors=TRUE) 



pc <- prcomp(ffnorm_og,scale. = FALSE)
eigenvalues <- pc$sdev^2
eigen_df <- data.frame(PC = paste0("PC", 1:length(eigenvalues)), Eigenvalue = eigenvalues)
eigen_df$PC <- factor(eigen_df$PC, levels = paste0("PC", 1:length(eigenvalues)))
scree_plot1 <- 
eigen_df %>%
  summarize(PC=PC,Eigenvalue=Eigenvalue) %>%
  arrange(desc(Eigenvalue)) %>%
  ggplot(aes(x = PC, y = Eigenvalue)) +
 # geom_bar(stat = "identity", fill = "steelblue") +
  geom_line(group = 1, color = "red") +
  geom_point(color = "red") +
  geom_segment(x=0,y=2,xend=24,yend=1,linetype = "dotted",linewidth = 1)+
  annotate("label",x=4,y=2.5,label="Parallel Test",color="black")+
  labs(title = "Scree Plot", x = "Principal Components", y = "Eigenvalues") +
  theme_minimal()
# scree as a % of total variation
scree_plot2 <- 
prcomp(fantasy %>%
  select(where(is.numeric) & -ADP & -Year & -FantasyPointsPPR & -Rank & -PositionRank &
         !contains("scor", ignore.case = TRUE)), scale. = TRUE) %>%
  fviz_eig(addlabels = TRUE)

gridExtra::grid.arrange(scree_plot1,scree_plot2,ncol=2)

pc_og <- principal(ffnorm_og,nfactors=3,scores=TRUE,covar=FALSE,rotate="varimax") # default is varimax rotation
# pc_og$loadings
# print(as.matrix(pc_og$loadings), cutoff = 0) # seems to only account for 62% of the total variance 
# eigen(fantasy_cormatrix_og)$val/24
# 0.55743682334+0.37837352942+0.21494701803
# fantasy %>%
#   group_by(FantasyPosition) %>%
#   summarize(n=mean(FumblesLost))
# # PC1 = The QB Effect 
  
# fviz_pca_var(prcomp(ffnorm_og, scale. = FALSE), col.var = "black")

```

A parallel test was used to measure the number of components to obtain. The test performs the same decomposition on simulated data of the same size and graphs the results. Where the simulated and actual data intersect is the cutoff for the number of components to obtain. The results of the test suggest three components. The y-axis plots the eigenvalues which is the total variation explained by each component. In a simpler sense, it can be thought of as the number of original variables accounted for in that component (hence the horizontal line separating values less than one). Three principal components were obtained, acknowledging that principal component one (PC1) should account for approximately six variables, PC2 around 5, and PC3 around 3. The other scree plot better highlights the components as a percentage of total variability explained. Keep in mind that PC1 only accounts for 30% of the total variability and the first three components cumulatively account for 52% of total variability. It's likely that the post-hoc tests described in the methods section will not be sufficient for our goal since there is still half of the total variation not accounted for in these components. 

Scores are calculated for each individual player. Depending on how the components are defined, players can be ranked in ascending order. 

```{r,fig.width=12,fig.height=10,fig.align='center'}
test <- data.frame(pc_og$loadings[,c(1,2)])



test$variable <- row.names(test)
test_melt <- melt(test,id.vars = "variable")
colnames(test_melt) <- c("variable","component","value")
test_melt %>%
  mutate(component=fct_recode(component,PC1="RC1",PC2="RC2")) %>%
  ggplot(aes(x=variable,y=component,fill=value,label=round(value,2)))+
  geom_tile(color = "white") +
  geom_text(size=3,face="bold",color="black")+
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Loading") +
  theme_bw()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1),
        axis.title.x = element_blank()) +
  labs(title = "Principal Component Loadings",y="Principal Components")

```


## Principal Components - In-Game Stats
rotation: maximum variance 

**PC1 Definition: High-Volume Performing QBs**\
Attributes: Completions, Attempts, Passing Yards, Passing TDs, Interceptions, Fumbles\

1. PC1 would be attributed to high-volume QBs as they load extremely well for the above categories. The first inclination was to attribute PC1 to high performing quarter backs, however, that statement alone would be unjustifiable considering that interceptions and fumbles load extremely well to this component. High-volume quarter backs would be a more fitting description. These quarter backs are performing extremely well in some regard since it loads high for completions, passing yards, and passing touch downs. We can reason that these quarter backs are also able to consistently get the ball off of their hands. High-volume quarter backs will also load high to interceptions and fumbles. The more throws and attempts made, the more likely that fumbles and interceptions will occur. 
  
**PC2 Definition: Offensive Long Range Efficiency**\
Attributes: Games Started, Targets, Receptions, Receiving Yards, Receiving TDs\

2. PC2 can be attributed to total overall offensive efficiency given that we load extremely high for targets, receptions, receiving yards, and receiving    touchdowns. Players typically defined for this category would be wide receivers, and pc2 is measuring yardage efficiency. Efficiency is important in this context given that we also load high to targets, and even though it is not an inclusion criteria in fantasy scoring, it speaks to the aggressiveness on the offensive side. The key distinction to make here is that this describes the overall long range efficiency only, since rushing yards and touch downs are not accounted for in this component. Additionally, *overall* long range efficiency is justified since this must be a combination of quarter backs and the offensive line. Wide receivers, running backs, and tight ends will generally only score more touch downs and have more yards with a good quarter back. 
  
**PC3 Definition: Offensive Driving Efficiency**\
Attributes: Rushing Attempts, Rushing Yards, Rushing TDs\

3. PC3 would be attributed to mainly RBs and TEs that are elite drivers since they load high for rushing stats. 

Ideally, we'd want to load players that load high for all three categories. Considering the nature of football, depending on player's primary position, they will naturally perform better in certain stats or categories over others. In this case, there are multiple approaches to account for this. Actually, along every step I find there are ways that our paths diverge, but more on that later. One approach is to use only principal component one and players/scores that load high for that component to pick our quarter back. Principal components two and three would then be used for all other positions. I started with that approach but here comes the other divergence - how I choose the calculate the scores. There are two options under consideration. 

1. Include all variables in the principal component computation, with the benefit of providing a more comprehensive score but the drawback of added complexity.
2. Include only variables in the principal component computations that load high as the score, with the benefit of exclusively calculating how good they are at being good but the drawback of missing nuanced information capture in less significant variables. 

I tested the model starting with the second approach. First, I reviewed how the top ten quarter backs performed in 2022 by looking at their overall rank, position rank, the player, and the total fantasy points they had. 

```{r}
# test for pc1 
rank_actual <- 
fantasy %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR) %>%
  tibble()

rank_actual[1:10,]
```

Then we use the eigen values to calculate the principal component scores for each player, only including variables that loaded high. The players with the highest scores would be the highest performing QBs predicted for the 2022 season. Two things to note. Firstly, the position and overall rank will be the same here since we've define our first principal component as attributes of quarter backs only. Secondly, the model's fantasy points ppr would not be known. The purpose here is to calculate scores and draft in ascending order. We can, however, calculate the difference in fantasy points had we taken the models' picks. In the table, the model's fantasy points are the same as actual fantasy points to make this calculation easier. The results are shown below.

```{r, eval=TRUE,echo=FALSE,include=FALSE}

rank_pred <- 
fantasy %>%
  mutate(pc1 = (0.96755758*Completions)+(0.96979088*Attempts)+(0.96705865*PassingYards)
         +(0.93954025*PassingTDs)+(0.93859580*Interceptions)+(0.77179023*Fumbles)) %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR,pc1) %>%
  arrange(desc(pc1)) %>%
  tibble() %>%
  rename("Model_OverallRank" = "Rank",
         "Actual_PositionRank"="PositionRank",
         "Model_Player"="Player",
         "Model_FantasyPointsPPR"="FantasyPointsPPR",
         "Model_PCscore"="pc1") %>%
  mutate(Model_PositionRank = c(1:82),.before = Model_Player) %>%
  print(n=10)

rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])
knitr::kable(rank_diff)

```


Methods of measuring model performance: 

1. **Percentage of total players the model accurately selects.** If we were selecting quarter backs, we would use the first principal component scores to obtain the top 10 quarter backs in ascending order. We would then compare the results against the actual top 10 quarter backs for that season. In these results, 70% (7 out of 10 QBs) were accurately selected as being in the top 10 for total fantasy points. 

2. **Difference in total fantasy points of the top 20 players.** The top 20 players for each position are isolated using their associated principal component scores. The sum of the total fantasy points for the top 20 players are then subtracted from the what the actual total fantasy points for players in the top 20 in each position had to obtain the delta. 

3. **Absolute difference in position rank by player.** Each player will have the net difference in their position rank between the model and their actual rank for that season. In the above table, for example, the model selects Justin Herbert as #2 QB for fantasy but was actually #11 after the regular season, making the net -11.  

Now using the model's picks for the top ten quarter backs, 70% of those selected in the top 10 were actually in the top ten during the 2022 regular season. The total fantasy points for the quarter backs picked by the model were 3131.2. The total fantasy points the top ten quarter backs actually had was 3302 which means the model was off by 5% in regard to quarter back selection. The difference for rank by position are shown below. Players with a negative delta are those that were ranked higher in the model but came in lower after the season. Using a conservative threshold, MAE > 5, Top10 < 70%, and Fantasy Error > 5% will be used. If results are above or below this threshold, different measures should be taken to improve the model. 

```{r}
# 
# rank_diff %>%
#   mutate(PositionRankDelta=PositionRank-Actual_PositionRank) %>%
#   tibble() %>%
#   select(Model_Player,PositionRankDelta) %>%
#   print(n=10) %>%
#   abs(sum(n))
# 
 knitr::kable(tibble(FantasyPosition="QB",MAE=4,Top10="70%",FantasyError="5.1%"))

```

## Principal Components - Fantasy Weights

While the results are seemingly great, this was when I recalled that these principal components only account for half of the total variation. Considering that the goal of singular value decomposition via principal component is to maximize the total variation in the data, I had to think we can do much better. The first principal component which was attributed to quarter backs load high for interceptions and fumbles. While it is justifiable to reason that high-volume quarter backs will naturally intercept and fumble more often solely as a function of volume, would the *best* quarter backs really load high for those? To better understand this, the exact same process above was done to calculate new component scores, this time only including variables that are used for fantasy scoring. I first created these additional variables by multiplying them by my league's point system. For example, rushing touch downs were multiplied by six and became the new variable used for the svd. Those variables were passing yards, passing touchdowns, interceptions, rushing yards, rushing touchdowns, receptions, receiving yards, receiving touch downs, fumbles, and fumbles lost. 


```{r, eval=FALSE,echo=FALSE,include=FALSE}

# pc2
# actual
fantasy %>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR) %>%
  tibble() %>%
  print(n=10) # mostly WR RB like the pc analysis shows; top 10 are evenly split between teh best WR and best TE
# predicted
fantasy %>%
  mutate(pc2 = (0.732909476*Games)+(0.954222398*Targets)+(0.944470501*Receptions)+
           (0.956157602*ReceivingYards)+(0.882981792*ReceivingTDs))%>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc2) %>%
  arrange(desc(pc2)) %>%
  tibble() %>%
  print(n=10)


# pc3
fantasy %>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR) %>%
  tibble() %>%
  print(n=10) 

fantasy %>%
  mutate(pc3 = (0.961141891*RushingAttempts)+(0.966004285*RushingYards)+(0.910680715*RushingTDs)) %>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc3) %>%
  arrange(desc(pc3)) %>%
  tibble() %>%
  print(n=30)

pc_og$loadings[,3]

# using all variables 
fantasy %>%
  mutate(pc1 = pc_og$scores[,1],
         pc2 = pc_og$scores[,2],
         pc3 = pc_og$scores[,3],
         ovr = pc1+pc2+pc3) %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1,pc2,pc3,ovr) %>%
  arrange(desc(ovr)) %>%
  filter(FantasyPosition=="QB") %>%
  tibble() %>%
  print(n=100) %>%
  slice_max(FantasyPointsPPR,n=30) %>%
  summarize(sum(FantasyPointsPPR))
  

fantasy %>%
  mutate(pc1 = (0.96755758*Completions)+(0.96979088*Attempts)+(0.96705865*PassingYards)
         +(0.93954025*PassingTDs)+(0.93859580*Interceptions)+(0.77179023*Fumbles)) %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR,pc1) %>%
  arrange(desc(pc1)) %>%
  # tibble() %>%
  # print(n=30) %>%
  slice_max(pc1,n=30) %>%
  summarize(sum(FantasyPointsPPR))

```


### Results

The parallel test suggested three components were sufficient to explain the maximum variation in the data. 

```{r,fig.align='center'}

prcomp(ffnorm_score,scale.=FALSE) %>%
  fviz_eig(addlabels=TRUE)

```

The first three components alone account for 88.1% of the total variation within the data set, much better than the 50% obtained previously. The mean item complexity = 1.1. This means that each individual variable included in the principal components only load significantly on one component. This is the more ideal scenario since it makes defining the components much easier. Previously we had a mean item complexity of 1.5, meaning that half of the variables on average load significantly to two components. The first three components are then defined using a loading threshold of .7. 

```{r,fig.width=12,fig.height=10,fig.align='center'}

pc_scoring <- principal(ffnorm_score,nfactors=3,scores=TRUE,covar=FALSE,rotate="varimax") 

test <- data.frame(pc_scoring$loadings[,c(1:3)])
test$variable <- row.names(test)
test_melt <- melt(test,id.vars = "variable")
colnames(test_melt) <- c("variable","component","value")
test_melt %>%
  mutate(component=fct_recode(component,PC1="RC1",PC2="RC2",PC3="RC3")) %>%
  ggplot(aes(x=variable,y=component,fill=value,label=round(value,2)))+
  geom_tile(color = "white") +
  geom_text(size=3,face="bold",color="black")+
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Loading") +
  theme_bw()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1),
        axis.title.x = element_blank()) +
  labs(title = "Principal Component Loadings",y="Principal Components")

```

### Dimension Definitions
rotation: maximum variance 

**PC1 Definition: Low Performing QBs**\
Attributes: (-) Passing Yards, (-) Passing Touchdowns, (+) Fumbles, (+) Interceptions\

1. PC1 would be attributed to quite literally the least performing quarter backs. The significantly negative loadings for passing yards and touch downs mean that quarter backs that load high to this component are unable to score touch downs. Additionally, they load extremely high for fumbles and interceptions, a confirmation of their under performance in relevant categories. PC1 would only be attributed to quarter backs since these in-game stats are generally relevant to them alone. 
  
**PC2 Definition: High-Performing Distance Efficiency**\
Attributes: + Receiving Touchdowns, + Receiving Yards, + Receptions\

2. PC2 can be attributed to total overall offensive efficiency given that we load extremely high for receiving touchdowns, receiving yards, and receptions. Players that load high to this category are likely wide receivers since wide receivers are more used for long range plays. The key distinction to make here is that this describes the overall long range efficiency only, since rushing yards and rushing touch downs are not accounted for in this component. Additionally, *overall* long range efficiency would better describe this component, since this must be a combination of quarter backs and the offensive line. Wide receivers, running backs, and tight ends will generally only score more touch downs and have more yards with a better quarter back. 
  
**PC3 Definition: High-Performing Driving Efficiency**\
Attributes: + Rushing Touchdowns, + Rushing Yards\

3. PC3 would be attributed to overall driving efficiency in the same fashion. Likewise, this is also a combination of the offense line and the quarterback, considering that high performing drivers will still be unable to score touch downs in some fashion if their quarter back cannot perform. I would expect running backs and tight ends to load high to this category.  

The goal is to isolate players in these areas. 


```{r,fig.width=12,fig.height=10,fig.align='center'}
s <- prcomp(ffnorm_score,scale.=FALSE)

fviz_pca_biplot(s,
                    # Individuals
                
                    geom.ind = "point",
                    geom = c("arrow", "point"),
                    arrow.color = "black",
                    label = "var",
                    fill.ind = fantasy$FantasyPosition,
                    col.ind = "black",
                    pointshape = 21, 
                    pointsize = 1,
                    palette = "jco",
                    addEllipses = TRUE, 
                    repel = TRUE,
                    # Variables
                    alpha.var = "contrib", 
                    col.var = "black",
                    gradient.cols = "RdYlBu") +
  geom_rect(aes(xmin = -13.5, ymin = 0, xmax = -7.5, ymax = -3.5), 
            color = "grey30", 
            alpha = 0, 
            show.legend = FALSE) +  # Hide legend for this rect
  annotate("text", label = "Best Overall QBs", x = -12, y = -0.5, color = "grey30") +
  geom_rect(aes(xmin = 0.25, ymin = 1, xmax = 1, ymax = 1.75), 
            color = "grey30", 
            alpha = 0, 
            show.legend = FALSE) +  # Hide legend for this rect
  annotate("text", label = "Best Offensive \n long range players", x = -2.5, y = 2.5, color = "grey30") +
  geom_curve(aes(xend = 0.8, yend = 1.85, x = -2.8, y = 2.8), 
             color = "grey30", 
             arrow = arrow(), 
             curvature = -0.4, 
             show.legend = FALSE) 

```

The coordinate plane shows the first component on the x axis and the second on the y axis. The `scoring_` and associated arrows are the eigen vectors on this principal component space. An increase on the x axis, or the first principal component, we increase in *under* performance. We would want to obtain players that negatively contribute to this component ie quadrant three. In the same fashion, an increase on the y axis means an increase in long range efficiency. This can only show the first two components. Based on the above, the we'd use the first component for quarter backs, the second for wide receivers, and the third for tight ends and running backs. However, since WRs, TEs, and RBs are much more similar in position (which the model concurs via the boxed region in quadrant I) than QBs, those three positions were included and ranked for PC2 and PC3. This allows us to more effectively see the primary position and players the model decides to pick for each category. In summary, principal component one was used for quarter backs, principal components two and three were used for all other positions at first. An overall score was then calculated using PC2 and PC3 only. Players with the highest overall scores would load significantly well to PC2 and PC3. These players would be both the best of the best in both long-range and driving efficiency. This allows us to see what positions the model picks for long-range (PC2) and driving (PC3) efficiency. Note that this tells us what position would be the best at both but *does not* tell us if they are the best at both. 

```{r}
fantasy %>%
  mutate(pc1 = pc_og$scores[,1],
         pc2 = pc_og$scores[,2],
         pc3 = pc_og$scores[,3],
         pc2_3 = pc2+pc3,
         ovr = pc1+pc2+pc3) %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1,pc2,pc3,pc2_3,ovr) %>%
  filter(FantasyPosition!="QB") %>%
  group_by(FantasyPosition) %>%
  summarize(n=mean(pc2_3)) %>%
  arrange(desc(n))

```

We see that running backs and wide receivers on average have positive scores for both, meaning that they contribute positively to the second and third components (long and driving efficiency). Surprisingly, tight tends on average are negative in both regards. The model rarely selects tight ends across all three of these dimensions. The results from the model show that the best overall QBs via the lowest component scores should be selected for PC1, the best wide receivers for PC2, and the best RBs for PC3. Only a very select few tight ends are chosen for PC2 and PC3. Of the top 30 highest-performing players in long-range efficiency (PC2), 3 of them were tight ends and only 1 of them was in the top 10 - Travis Kelce. Of the top 30 highest-performing players in driving efficiency (PC3), only Taysom Hill (TE), made the cut. Since fantasy league members must select players for every position, the best approach would be to select QBs, WRs, and RBs only for PC1, PC2, and PC3 respectively and then address tight ends afterwards. That same process was followed to compare the model's picks using against their actuals for 2022. The results for the three positions are shown below. 

### Model Picks
#### PC1 - QBs

```{r}
pc_scoring <- principal(ffnorm_score,nfactors=3,scores=TRUE,covar=TRUE,rotate="varimax") 

# fantasy %>%
#   mutate(pc1 = (-.956*scoring_PassingYards)+(-.94*scoring_PassingTDs)+(.933*scoring_Interceptions)+
#            (0.850*scoring_Fumbles)+(0.711*scoring_FumblesLost)) %>%
#   filter(FantasyPosition=="QB") %>%
#   select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1) %>%
#   arrange(pc1) %>%
#   tibble()

rank_actual <- 
fantasy %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR) %>%
  rename("Actual_PositionRank"="PositionRank", "Actual_OvrRank"="Rank","Actual_FantasyPointsPPR"="FantasyPointsPPR") %>%
  tibble()

rank_pred <- 
fantasy %>%
  mutate(pc1 = (-.956*scoring_PassingYards)+(-.94*scoring_PassingTDs)+(.933*scoring_Interceptions)+
           (0.850*scoring_Fumbles)+(0.711*scoring_FumblesLost)) %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR,pc1) %>%
  arrange(pc1) %>%
  tibble() %>%
  rename("Model_OverallRank" = "Rank",
       #  "Actual_PositionRank"="PositionRank",
         "Model_Player"="Player",
         "Model_FantasyPointsPPR"="FantasyPointsPPR",
         "Model_PCscore"="pc1") %>%
  mutate(Model_PositionRank = c(1:82),.before = Model_Player) 

rank_diff <- cbind.data.frame(rank_actual,rank_pred)


rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])

knitr::kable(rank_diff)

```



```{r}
rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])

rank_diff %<>%
  mutate(PositionRankDelta=Model_PositionRank-PositionRank) %>%
  tibble() 

pc_fw_modelerror_qb <- tibble(FantasyPosition="QB",MAE=sum(abs(rank_diff$PositionRankDelta))/10,Top10="70%",FantasyError="5.1%")
```


The results are nearly identical to the previous method (on the original variables). Model accurately picks seven of the top ten players.

#### PC2 - WR

```{r}
pc_scoring <- principal(ffnorm_score,nfactors=3,scores=TRUE,covar=FALSE,rotate="varimax") 

# fantasy %>%
#   mutate(pc2 = (0.958*scoring_Receptions)+(0.976*scoring_ReceivingYards)+(.923*scoring_ReceivingTDs)) %>%
#   filter(FantasyPosition=="WR") %>%
#   select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc2) %>%
#   arrange(desc(pc2)) %>%
#   tibble() %>%
#   print(n=30)


rank_actual <- 
fantasy %>%
  filter(FantasyPosition=="WR") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR) %>%
  rename("Actual_PositionRank"="PositionRank", "Actual_OvrRank"="Rank","Actual_FantasyPointsPPR"="FantasyPointsPPR") %>%
  tibble()

rank_pred <- 
fantasy %>%
  filter(FantasyPosition=="WR") %>%
  mutate(pc2 = (0.958*scoring_Receptions)+(0.976*scoring_ReceivingYards)+(.923*scoring_ReceivingTDs)) %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR,pc2) %>%
  arrange(desc(pc2)) %>%
  tibble() %>%
  rename("Model_OverallRank" = "Rank",
        # "Actual_PositionRank"="PositionRank",
         "Model_Player"="Player",
         "Model_FantasyPointsPPR"="FantasyPointsPPR",
         "Model_PCscore"="pc2") %>%
  mutate(Model_PositionRank = c(1:218),.before = Model_Player)

rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])
knitr::kable(rank_diff)

```


```{r}
rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])


rank_diff %<>%
  mutate(PositionRankDelta=Model_PositionRank-PositionRank) %>%
  tibble() 




pc_fw_modelerror_wr <- tibble(FantasyPosition="WR",MAE=sum(abs(rank_diff$PositionRankDelta))/10,Top10="100%",FantasyError="2.3%") # MAE = 5.7
```

#### PC3 - RB 

```{r}
pc_scoring <- principal(ffnorm_score,nfactors=3,scores=TRUE,covar=FALSE,rotate="varimax") 

# fantasy %>%
#   mutate(pc3 = (0.96108684*scoring_RushingYards)+(0.93945216*scoring_RushingTDs)) %>%
#   filter(FantasyPosition=="RB") %>%
#   select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc3) %>%
#   arrange(desc(pc3)) %>%
#   tibble() %>%
#   print(n=30)


rank_actual <- 
fantasy %>%
  filter(FantasyPosition=="RB") %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR) %>%
  rename("Actual_PositionRank"="PositionRank", "Actual_OvrRank"="Rank","Actual_FantasyPointsPPR"="FantasyPointsPPR") %>%
  tibble()

rank_pred <- 
fantasy %>%
  filter(FantasyPosition=="RB") %>%
  mutate(pc3 = (0.96108684*scoring_RushingYards)+(0.93945216*scoring_RushingTDs)) %>%
  select(Rank,PositionRank,Player,FantasyPointsPPR,pc3) %>%
  arrange(desc(pc3)) %>%
  tibble() %>%
  rename("Model_OverallRank" = "Rank",
       #  "Actual_PositionRank"="PositionRank",
         "Model_Player"="Player",
         "Model_FantasyPointsPPR"="FantasyPointsPPR",
         "Model_PCscore"="pc3") %>%
  mutate(Model_PositionRank = c(1:162),.before = Model_Player) 

rank_diff <- cbind.data.frame(rank_actual[1:10,],rank_pred[1:10,-1])
knitr::kable(rank_diff)

```

#### Model Accuracy

```{r}

rank_diff %<>%
  mutate(PositionRankDelta=Model_PositionRank-PositionRank) %>%
  tibble()


pc_fw_modelerror_rb <- tibble(FantasyPosition="RB",MAE=sum(abs(rank_diff$PositionRankDelta))/10,Top10="60%",FantasyError="4.5%")

knitr::kable(rbind(pc_fw_modelerror_qb,pc_fw_modelerror_rb,pc_fw_modelerror_wr))


```

The table shows model accuracy against 2022 actual data. Starting with the mean absolute error, this measures the average difference in rankings for total fantasy points between the model and the actual year. On average, across the three positions, the model is off by 3 - very good for fantasy purposes. Even those who not the sport extremely well will draft players based on emotion, sentiment, or loyalty in some fashion, and having these insights and potential edge (if there is then evidence the scores generalizes well to future seasons) will definitely be an advantage. There are still some areas for improvement, such as the model only accurately selecting 7 of the top 10 players in fantasy points for quarter backs, and 6 of 10 for running backs. Normally, process steps would be reviewed for different ways to improve the model, but in the interest of time that will not be done here. Now that I'm currently in a position where I like the results, what does the next step look like and how can we apply this for the 2024 draft given that draft day is in 24 hours? This is the hardest part. SVD via PCA is commonly done in the post exploratory phase as a part of an ensemble of methods in which predictive models/machine learning methods are then layered on top of it depending on the goal of the research. With my goal of creating the fantasy team with the highest likelihood (albeit unknown) of obtaining the most fantasy points, I outlined different approaches one could take given where I am in the process and knowing that I only have 24 hours left.

**1. Using 2022 PCA Scores to Rank Players and Compare to 2023 Actual**

Process

PCA on 2022 Data:
Perform PCA on 2022 in-game stats.
Obtain principal component (PC) scores for each player, focusing on the first few principal components (e.g., PC1, PC2).
Rank players based on their PC scores (e.g., higher scores on PC1 may indicate better performance).

Ranking and Testing:
Compare the PCA-derived ranks from 2022 to the actual fantasy points scored by each player in 2023.
Evaluate the accuracy of these ranks by calculating metrics like precision or correlation between PCA ranks and actual points.
Generalization:

If 2022 PCA ranks generalize well to 2023 performance, use the same method on 2023 data.
Apply this PCA-based ranking approach to the 2024 player pool to predict future performance.

**2. Combining 2022 and 2023 Data for PCA and Regression**

Process

Data Preparation:
Combine the 2022 and 2023 data sets, including in-game stats and calculated fantasy points.
Standardize the data to ensure comparability.
PCA on Combined Data:

Perform PCA on the combined data set to capture the underlying structure across both years.
Extract PC scores for each player, focusing on the first few components (e.g., PC1, PC2, PC3).
Regression Analysis:

Use the PC scores as features in a regression model along with other in-game stats (e.g., games started, targets).
Train the model on 2022 and 2023 data to predict total fantasy points.
Projection for 2024:

Input 2024 projection data into the trained regression model to predict total fantasy points for each player in 2024.
Rank players based on these predictions.

**3. Using 2024 Projection Data to Calculate PCA Scores**

Process

PCA on 2024 Projection Data:
Perform PCA on the 2024 projected in-game stats.
Obtain PC scores for each player based on the projections.
Ranking Based on Projections:

Rank players based on their PC scores from the 2024 projection data.
Use these rankings to guide draft decisions.

Assumptions:
This approach assumes that the 2024 projections are accurate enough to reflect actual performance, so PC scores from projections should correlate with final fantasy points.


**4. Weighted PCA Combining Historical and Projected Data**

Process

Weighting and Combining Data:
Assign weights to the 2022, 2023, and 2024 (projected) data. For example, use a higher weight for more recent years like 2023.
Combine the data sets into a single matrix, with projections and historical data weighted accordingly.

PCA on Weighted Data:
Perform PCA on the weighted data set to capture the combined effect of historical and projected performance.
Obtain PC scores for each player, reflecting a blend of past performance and future projections.
Ranking and Drafting:

Rank players based on the weighted PC scores.
Use these ranks to inform drafting decisions.

```{r, echo=FALSE, eval=FALSE,warning=FALSE,include=FALSE}

fviz_scre

fa.parallel(fantasy_cormatrix_scoring,n.iter=100,fa="pc", main="Parallel Scree")

# PA suggests 3 components

pc_scoring <- principal(ffnorm_score,nfactors=3,scores=TRUE,covar=FALSE,rotate="varimax") 

# RMSE = .99; cumulative explaind variance 88%; Mean item complexity is 1.1 as opposed to original 1.5 meaning interpretation is much easier as all variables load to only one component

print(pc_scoring$loadings,cutoff=0)

s <- prcomp(ffnorm_score,scale.=FALSE)

fviz_pca_biplot(s,
                    # Individuals
                    geom.ind = "point",
                    geom = c("arrow", "point"),
                    arrow.color = "black",
                    label = "var",
                    fill.ind = fantasy$FantasyPosition,
                    col.ind = "black",
                    pointshape = 21, 
                    pointsize = 1,
                    palette = "jco",
                    addEllipses = TRUE, 
                    repel = TRUE,
                    # Variables
                    alpha.var = "contrib", 
                    col.var = "black",
                    gradient.cols = "RdYlBu") +
  geom_rect(aes(xmin = -13.5, ymin = 0, xmax = -7.5, ymax = -3.5), 
            color = "grey30", 
            alpha = 0, 
            show.legend = FALSE) +  # Hide legend for this rect
  annotate("text", label = "Best Overall QBs", x = -12, y = -0.5, color = "grey30") +
  geom_rect(aes(xmin = 0.25, ymin = 1, xmax = 1, ymax = 1.75), 
            color = "grey30", 
            alpha = 0, 
            show.legend = FALSE) +  # Hide legend for this rect
  annotate("text", label = "Best Offensive \n long range players", x = -2.5, y = 2.5, color = "grey30") +
  geom_curve(aes(xend = 0.8, yend = 1.85, x = -2.8, y = 2.8), 
             color = "grey30", 
             arrow = arrow(), 
             curvature = -0.4, 
             show.legend = FALSE)  # Hide legend for this curve
    
fantasy %>%
  mutate(pc1 = (-.956*scoring_PassingYards)+(-.94*scoring_PassingTDs)+(.933*scoring_Interceptions)+
           (0.850*scoring_Fumbles)+(0.711*scoring_FumblesLost)) %>%
  filter(FantasyPosition=="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1) %>%
  arrange(pc1) %>%
  tibble() %>%
  print(n=20)


fantasy %>%
  mutate(pc2 = (0.958*scoring_Receptions)+(0.976*scoring_ReceivingYards)+(.923*scoring_ReceivingTDs)) %>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc2) %>%
  arrange(desc(pc2)) %>%
  tibble() %>%
  print(n=50) # couple TEs in the mix, 1 RB but mostly WRs as typical



fantasy %>%
  mutate(pc3 = (0.961*scoring_RushingYards)+(0.939*scoring_RushingTDs)) %>%
  filter(FantasyPosition!="QB") %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc3) %>%
  arrange(desc(pc3)) %>%
  tibble() %>%
  print(n=50)

# using all variables 

fantasy %>%
  mutate(pc1 = pc_og$scores[,1],
         pc2 = pc_og$scores[,2],
         pc3 = pc_og$scores[,3],
         ovr = pc1+pc2+pc3) %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1,pc2,pc3,ovr) %>%
  arrange(desc(ovr)) %>%
  #filter(FantasyPosition=="QB") %>%
  tibble() %>%
  print(n=20) %>%
  slice_min(FantasyPointsPPR,n=30) %>%
  summarize(sum(FantasyPointsPPR))

# BIPLOT


s <- prcomp(ffnorm_score,scale. = FALSE)

prcomp(ffnorm_score,scale.=FALSE)$val

# str(iris)
s$rotation[,c(2,3)]
# s <- data.frame(s$x)

# dim(s)
fviz_pca_biplot(s,
                    # Individuals
                    geom.ind = "point",
                    axes = c(3,2),
                    fill.ind = fantasy$FantasyPosition,
                    col.ind = "black",
                    pointshape = 21, pointsize = 1,
                    palette = "jco",
                    addEllipses = TRUE, 
                    # Variables
                    alpha.var ="contrib", col.var = NA,
                    gradient.cols = "RdYlBu")+geom_label("text",x=5,y=7,label="some text")


# BY POSITION 

fantasy %>%
  mutate(pc1 = pc_og$scores[,1],
         pc2 = pc_og$scores[,2],
         pc3 = pc_og$scores[,3],
         ovr = pc1+pc2+pc3) %>%
  select(Rank,PositionRank,FantasyPosition,Player,FantasyPointsPPR,pc1,pc2,pc3,ovr) %>%
  arrange(desc(ovr)) %>%
  tibble() %>%
  print(n=100)
  

# DRAFT ORDER QB > RB > WR > TE 

```

# 2023 | 2022 NFL seasons

The weighted PCA approach on both the '22 and '23 NFL regular season was used to select my fantasy team. After matching corresponding players in 2023, both years were joined such that statistics from both years were available for each observation per player. A weighted average of the `scoring_` variables were then calculated consisting of a third of their statistics from '22 and two-thirds from '23, emphasizing recent seasons at a 2:1 ratio. This weight only applies to the athletes that played at least one game in both years. A total of 39 athletes that had season ending injuries in '22 but played in '23 were omitted from the data. No weight was applied to the 142 rook athletes in 2023. 100% of their '23 NFL season was incorporated into their component scores for rook athletes, given that there is no other history (besides this one) for a baseline. Using combine data was considered, but was not used in the interest of time. Exploratory analysis showed that the both the mean and spread of the underlying distributions for all in-game statistics were extremely similar between '23 and '24. For '23 fantasy points, the mean was 83.1 (sd = 87.3).


```{r}
########################### 2023 NFL import and clean
# fantasy2023 <- data.frame(read.xlsx("Fantasy Football Data/archive/fantasy_mergedsource_2023.xlsx"))
# fantasy2023 %<>% mutate(Player=gsub("\\*","",Player),
#                         Player=gsub("\\+","",Player))
fantasy2023 <- read.xlsx("Fantasy Football Data/archive/fantasy2023.xlsx") %>% data.frame()

fantasy2023 %<>%
  rename(
    Rank = Rk,
    Player = Player,
    Team = Tm,
    FantasyPosition = FantPos,
    Age = Age,
    Games = G,
    GamesStarted = GS,
    Completions = Cmp, #QB
    Attempts = Att, #QB
    PassingYards = Yds, # SCORING: (*1/25)
    PassingTDs = TD, # SCORING: (*4)
    Interceptions = Int, # SCORING: (*-2)
    RushingAttempts = RushAtt,
    RushingYards = RushYds,  # SCORING: (*1/10)
    YardsPerAttempt = YA, # ***Rushing Yards / Rushing Attempts 
    RushingTDs = RushTD, # SCORING(*6)
    Targets = Tgt, # TE/WR no. times player is thrown ball 
    Receptions = Rec, # no. passes caught; SCORING: (*1)
    ReceivingYards = RecYds, # SCORING: (*.1)
    YardsPerReception = YR, # ***Receiving Yards / Receptions ; complete rate = .85
    ReceivingTDs = RecTD, # SCORING: (*6)
    Fumbles = Fmb, # SCORING: (*-2)
    FumblesLost = FL, # no times player fumbles and opp team receives; SCORING: (*-2)
    FantasyPointsPPR = PPR, # no fantasy pts in a points per reception league
    PlayerID = PlayerID,
    PositionRank = PosRank, # ranking grouped by position
    Year = Year
  )


fantasy2023 %<>% mutate(across(c(1,5:26),as.numeric))

fantasy2023 %<>% mutate(
  YardsPerRushAttempt = RushingYards / RushingAttempts, # duplicate 
  CompletionsPerAttempt = Completions / Attempts,
  TDsPerAttempt = PassingTDs / Attempts,
  InterceptionsPerAttempt = Interceptions / Attempts,
  TDsPerReception = ReceivingTDs / Receptions, # complete r = .85
  FumblesLostPerFumble = FumblesLost / Fumbles, .after = PlayerID # complete rate = .4
)

fantasy2023 %<>% mutate(Team = factor(Team), FantasyPosition = factor(FantasyPosition))

# including scoring 

fantasy2023 %<>% mutate(
  scoring_PassingYards = PassingYards*.04,
  scoring_PassingTDs = PassingTDs*4,
  scoring_Interceptions = Interceptions*(-2),
  scoring_RushingYards = RushingYards*(.01),
  scoring_RushingTDs = RushingTDs*6,
  scoring_Receptions = Receptions*1,
  scoring_ReceivingYards = ReceivingYards*.1,
  scoring_ReceivingTDs = ReceivingTDs*6,
  scoring_Fumbles = Fumbles*(-2),
  scoring_FumblesLost = FumblesLost*(-2)
)

fantasy2023 %<>% mutate(across(where(is.numeric), ~replace(., is.na(.), 0)))
fantasy2023 %<>% filter(FantasyPosition!="FB")
fantasy2023 %<>% filter(!PlayerID %in% c("FlacJo00","MoreFo00"))


names(fantasy) <- paste0(names(fantasy),"2022")
names(fantasy2023) <- paste0(names(fantasy2023),"2023")


combine <- 
  fantasy2023 %>%
  left_join(fantasy,join_by("PlayerID2023"=="PlayerID2022"),keep=TRUE) %>%
  data.frame()


rookies23 <- 
  combine %>%
  filter(is.na(PlayerID2022),is.na(PlayerID2023)) 
  
injured22_played23 <- 
  combine %>%
  filter(!is.na(PlayerID2023),is.na(Games2022)) %>%
  tibble()

combine %<>%
  anti_join(injured22_played23,by="PlayerID2023") # filter out inj222_player23
  
combine %<>%
  mutate(PlayerID2022 = case_when(is.na(PlayerID2022) ~ '0', .default = PlayerID2022),
         PlayerID2023 = case_when(is.na(PlayerID2023) ~ '0', .default = PlayerID2023)) 

combine %<>% 
  mutate(weighted_PassingYards =case_when(PlayerID2023=='0' ~ scoring_PassingYards2023,
                                             PlayerID2023!='0' ~ 1/3*scoring_PassingYards2022 + 2/3*scoring_PassingYards2023),
         weighted_PassingTDs =case_when(PlayerID2023=='0' ~ scoring_PassingTDs2023,
                                             PlayerID2023!='0' ~ 1/3*scoring_PassingTDs2022 + 2/3*scoring_PassingTDs2023),
         weighted_Interceptions =case_when(PlayerID2023=='0' ~ scoring_Interceptions2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_Interceptions2022 + 2/3*scoring_Interceptions2023),
         weighted_RushingYards =case_when(PlayerID2023=='0' ~ scoring_RushingYards2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_RushingYards2022 + 2/3*scoring_RushingYards2023),
         weighted_RushingTDs =case_when(PlayerID2023=='0' ~ scoring_RushingTDs2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_RushingTDs2022 + 2/3*scoring_RushingTDs2023),
         weighted_Receptions =case_when(PlayerID2023=='0' ~ scoring_Receptions2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_Receptions2022 + 2/3*scoring_Receptions2023),
         weighted_ReceivingYards =case_when(PlayerID2023=='0' ~ scoring_ReceivingYards2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_ReceivingYards2022 + 2/3*scoring_ReceivingYards2023),
         weighted_ReceivingTDs =case_when(PlayerID2023=='0' ~ scoring_ReceivingTDs2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_ReceivingTDs2022 + 2/3*scoring_ReceivingTDs2023),
         weighted_Fumbles =case_when(PlayerID2023=='0' ~ scoring_Fumbles2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_Fumbles2022 + 2/3*scoring_Fumbles2023),
         weighted_FumblesLost =case_when(PlayerID2023=='0' ~ scoring_FumblesLost2023,
                                           PlayerID2023!='0' ~ 1/3*scoring_FumblesLost2022 + 2/3*scoring_FumblesLost2023))
  
```

## Results

Parallel and scree tests were performed on the weighted averages of the variables used for `FantasyPointsPPR.` The parallel test showed three components were sufficient but as many as four could be used according to the scree test. The calculated eigen values of the first three components cumulatively explain 90.1% of the total variation within the data. 

```{r,fig.align='center'}
# cor | std scale

combine_norm <- combine %>%
  select(contains("weighted",ignore.case=TRUE)) %>%
  mutate_all(scale.default)



combine_cor_matrix <- combine %>%
  select(contains("weighted",ignore.case=TRUE)) %>%
  cor()


# parallel test

#fa.parallel(combine_norm,n.iter=100,fa="pc",error.bars = TRUE) # suggest 3 components; pc1 ~ 5 ev, pc2 ~ 3, pc3 = 1.5

prcomp(combine_norm, scale. = FALSE) %>%
  fviz_eig(addlabels = TRUE) # 89 % of total variation between both years explained !
```

The standardized loadings were then plotted on a patter correlation matrix to define the components. The loading score for each component were extremely similar in value to ones obtained in the Fantasy Weights section. Components were defined using these definitions. 

```{r,fig.width=12,fig.height=10,fig.align='center'}
# scree
####### principal components 

pc_weight <- principal(combine_cor_matrix,nfactors=3,rotate="varimax",covar = TRUE)
# cum var b/w pc1-pc3 = 91%
# mean item complexity = 1; rmsr = .04

### pc definitions 

test <- data.frame(pc_weight$loadings[,c(1:3)])
test$variable <- row.names(test)
test_melt <- melt(test,id.vars = "variable")
colnames(test_melt) <- c("variable","component","value")
test_melt %>%
  mutate(component=fct_recode(component,PC1="RC1",PC2="RC2",PC3="RC3")) %>%
  ggplot(aes(x=variable,y=component,fill=value,label=round(value,2)))+
  geom_tile(color = "white") +
  geom_text(size=3,face="bold",color="black")+
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Loading") +
  theme_bw()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1),
        axis.title.x = element_blank()) +
  labs(title = "Principal Component Loadings",y="Principal Components")
```

rotation: maximum variance 

**PC1 Definition: Low Performing QBs**\
Attributes: (-) Passing Yards, (-) Passing Touchdowns, (+) Fumbles, (+) Interceptions\

1. PC1 would be attributed to the worst overall performing quarter backs. The significantly negative loadings for passing yards and touch downs mean that quarter backs that load high to this component are unable to score touch downs. Additionally, they load extremely high for fumbles and interceptions, a confirmation of their under performance in relevant categories. PC1 would only be attributed to quarter backs since these in-game stats are generally relevant to them alone. When calculating scores for PC1, the highest-performing or best overall quarter backs would have the lowest scores, since they would negatively contribute to this component. 
  
**PC2 Definition: High-Performing Distance Efficiency**\
Attributes: + Receiving Touchdowns, + Receiving Yards, + Receptions\

2. PC2 can be attributed to total overall offensive efficiency given that we load extremely high for receiving touchdowns, receiving yards, and receptions. Players that load high to this category are likely wide receivers since wide receivers are more used for long range plays. The key distinction to make here is that this describes the overall long range efficiency only, since rushing yards and rushing touch downs are not accounted for in this component. Additionally, *overall* long range efficiency would better describe this component, since this must be a combination of quarter backs and the offensive line. Wide receivers, running backs, and tight ends will generally only score more touch downs and have more yards with a better quarter back. 
  
**PC3 Definition: High-Performing Driving Efficiency**\
Attributes: + Rushing Touchdowns, + Rushing Yards\

3. PC3 would be attributed to overall driving efficiency in the same fashion. Likewise, this is also a combination of the offense line and the quarterback, considering that high performing drivers will still be unable to score touch downs in some fashion if their quarter back cannot perform. I would expect running backs and tight ends to load high to this category. 

The annotations show what regions in each component would isolate the best (or worst) quarter backs for PC1 and the best long-range players for PC2. The benefit of plotting components as functions of each other is to understand the variability between two dimensions individually. Comparing PC1 and PC2 in this manner may not be necessary considering how we've defined the components, but visualizing it this way highlights any outliers and spread of the data. The ellipses are the regions that represent the 95% confidence interval for each fantasy position. Looking at PC1 and its associated eigen vectors, it is evident that the best quarter backs would be those that have high values along the x-axis (note that quarter backs are the only group spread differently than the others, evidence that this component are attributes of them). Although the individual component scores for these quarter backs will be negative (as they negatively contribute to this component), these are orthogonal projections, so the fact that it is 'positive' on the x axis here is meaningless. The interpretation would be identical if we flipped it over the y axis. The three quarter backs we *definitely* want to obtain are the three outliers closest to the top of the annotated box. These quarter backs would be something akin to the 'best of the best'. The other important part of this relates to PC2. The underlying variables that contribute the most to this component are receptions, receiving yards, and receiving touch downs. This is the 'long-range' cateogry (rushing yards and tds are not accounted for here). In the previous biplot, wide receivers completely dominated this region when it came to individual component scores of athletes. While that is somewhat the case here, notice that running backs are not far behind. Athletes highest in y values are still the wide receivers, but there is a good region of running backs [2,2.5] on the x axis that contribute just as well as wide receivers. 


```{r,fig.width=12,fig.height=10,fig.align='center'}

### pc biplot

s <- prcomp(combine_norm,scale.=FALSE)
pc_weight_total <- principal(combine_norm,nfactors=3,rotate="varimax",covar=TRUE)



fviz_pca_biplot(s,
                # Individuals
                axes = c(1,2),
                geom.ind = "point",
                geom = c("arrow", "point"),
                arrow.color = "black",
                label = "var",
                fill.ind = combine$FantasyPosition2023,
                col.ind = "black",
                pointshape = 21, 
                pointsize = 1,
                palette = "jco",
                addEllipses = TRUE, 
                repel = TRUE,
                # Variables
                alpha.var = "contrib", 
                col.var = "black",
                gradient.cols = "RdYlBu") + # PC1 == QB ; PC2
  annotate("text", label = "Best Overall QBs", x = 10.2, y = 2.8, color = "red4") +
  geom_rect(aes(xmin = 7.5, ymin = 0, xmax = 15.3, ymax = 2.65), 
            color = "red4", 
            alpha = 0, 
            show.legend = FALSE) +  # Hide legend for this rect
  annotate("text", label = "Best Offensive long range players", x = 7.8, y = 7.3, color = "red4")+
  annotate("text", label = "*WRs/RBs with WRs dominating", x = 9.8, y = 7, color = "red4", size = 2)+
  geom_curve(aes(xend = 2.5, yend = 4.1, x = 6, y = 7.1),
             arrow=arrow(),
             curvature = 0, color = "red4")+
  geom_curve(aes(xend = -.3, yend = 5.3, x = 6, y = 7.1),
             arrow=arrow(),
             curvature = 0, color = "red4")

```


Understanding the variability between two dimensions individually would be the most beneficial between PC2 and PC3 since it would easily highlight players that are the best at both. The dynamic sport of football and the physical build of players makes it extremely difficult to be an efficient driving scorer and an efficient passing scorer (receiving). Running backs tend to do well in the driving aspect; they have stockier frames making easier to drive through defenses and gain yardages that way. Wide receivers do well on the receiving end - they have slimmer frames leading to elusive plays to gain the most yardage (hail marys' as an polar example). Players that contribute equally well to PC2 and PC3 are wraps for fantasy (granted they have a good quarter back). 

The same trend identified in the component definitions are seen here. The region with the highest x values are wide receivers (tip of 95% CI extends out the most) with a handful of outliers near the max. The region with the highest y values, representing PC3, is nearly reserved for running backs (except for a couple exceptions). Notice that there are almost no players that positively contribute to PC3. I can physically count by hand the six players that positively contribute for PC3 that are not running backs. There are two parts of this graph to pay attention to. Firstly, the red box indicates the top of the 95% confidence interval for running backs ie the best of the best for PC3. Players in this region should be selected in the fantasy draft. More importantly, there is one identified that contributes extremely well to both PC2 and PC3. The vertical line separates the top six NFL athletes for long range efficiency, who are wide receivers (using a weighted average of '22 and '23 seasons), but there is only one running back out of the entire NFL offense that is in this category but also one of the best in driving efficiency. Take a guess whom that is. 
 
```{r,fig.width=12,fig.height=10,fig.align='center'}

fviz_pca_biplot(s,
                # Individuals
                axes = c(2,3),
                geom.ind = "point",
                geom = c("arrow", "point"),
                arrow.color = "black",
                label = "var",
                fill.ind = combine$FantasyPosition2023,
                col.ind = "black",
                pointshape = 21, 
                pointsize = 1,
                palette = "jco",
                addEllipses = TRUE, 
                repel = TRUE,
                # Variables
                alpha.var = "contrib", 
                col.var = "black",
                gradient.cols = "RdYlBu") +
  geom_vline(xintercept=5.3,color="red4")+
  geom_rect(aes(xmin=1.75,ymin=7,xmax=2.6,ymax=4.9),color="red4",alpha=0)

```

## Model Picks

There are two different ways of calculating overall scores (ie principal component scores) for each player to identify the players that should be drafted for this season. The first is to only use variables that contribute within the empirical range (+/-.75). Usually, the empirical range is only used to define what the principal components are or represent. Generally all scores should be used when calculating scores, the benefit being that it captures the combined variance of all the variables and the overall score is the more accurate reflection. The one drawback with this approach is that it complicates the model. The benefit of using only variables that are outside the empirical threshold is that it simplifies the model and is easier to interpret. Note that when interpreting the visualizations in this analysis, specifically the biplots, all component scores need to be included in the calculation. I will show the picks using both methods. 

### Approach 1 - Empirical Threshold
#### QBs

```{r}
qb_table <- 
combine %>%
  filter(FantasyPosition2023=="QB") %>%
  mutate(pc1 = (-0.96567341*weighted_PassingYards)+(-0.94166132*weighted_PassingTDs)+
           (0.94020552*weighted_Interceptions)+(0.87794884*weighted_Fumbles)+(0.80126198*weighted_FumblesLost)) %>%
  select(Rank2023,PositionRank2023,Player2023,FantasyPointsPPR2023,pc1) %>%
  arrange(pc1) %>%
  tibble() 
knitr::kable(qb_table[1:20,])
```

#### WRs

```{r}
wr_table <- 
combine %>%
  group_by(Player2023) %>%
  filter(FantasyPosition2023=="WR") %>%
  mutate(pc2 = (0.962317103*weighted_Receptions)+(0.980608513*weighted_ReceivingTDs)+(0.980608513*weighted_ReceivingYards)) %>%
  select(Rank2023,PositionRank2023,Player2023,FantasyPointsPPR2023,pc2) %>%
  arrange(desc(pc2)) 
knitr::kable(wr_table[1:20,])

```

#### RBs

```{r}
rb_table <- 
combine %>%
  filter(FantasyPosition2023=="RB") %>%
  mutate(pc3 = (weighted_RushingYards*0.96620788)+(weighted_RushingTDs*0.93854323)) %>%
  select(Rank2023,PositionRank2023,Player2023,FantasyPointsPPR2023,pc3) %>%
  arrange(desc(pc3)) %>%
  tibble() 
knitr::kable(rb_table[1:20,])

```


### Approach 2 - All Scores (Most Accurate)
#### QBs

```{r}
qb_pctable <- 
combine %>%
  mutate(pc1=pc_weight_total$scores[,1],
         pc2=pc_weight_total$scores[,2],
         pc3=pc_weight_total$scores[,3],
         ovr=-pc1+pc2+pc3) %>%
  select(Rank2023,PositionRank2023,FantasyPosition2023,Player2023,FantasyPointsPPR2023,pc1,pc2,pc3,ovr) %>%
  filter(FantasyPosition2023=="QB") %>%
  arrange(pc1) %>%
  tibble() 
knitr::kable(qb_pctable[1:20,])
```

#### WRs
```{r}
wr_pctable <- 
  combine %>%
  mutate(pc1=pc_weight_total$scores[,1],
         pc2=pc_weight_total$scores[,2],
         pc3=pc_weight_total$scores[,3],
         ovr=-pc1+pc2+pc3) %>%
  select(Rank2023,PositionRank2023,FantasyPosition2023,Player2023,FantasyPointsPPR2023,pc1,pc2,pc3,ovr) %>%
  filter(FantasyPosition2023=="WR") %>%
  arrange(desc(pc2)) %>%
  tibble() 
knitr::kable(wr_pctable[1:20,])
```

#### RBs
```{r}
rb_pctable <- 
  combine %>%
  mutate(pc1=pc_weight_total$scores[,1],
         pc2=pc_weight_total$scores[,2],
         pc3=pc_weight_total$scores[,3],
         ovr=-pc1+pc2+pc3,
         pc2_3=pc2+pc3) %>%
  select(Rank2023,PositionRank2023,FantasyPosition2023,Player2023,FantasyPointsPPR2023,pc1,pc2,pc3,pc2_3,ovr) %>%
  filter(FantasyPosition2023=="RB") %>%
  arrange(desc(pc3)) %>%
  tibble() 
knitr::kable(rb_pctable[1:20,])
```

For those who guessed right, *Christian McCaffrey* is the answer. 

#### TEs
```{r}
te_pctable <- 
  combine %>%
  mutate(pc1=pc_weight_total$scores[,1],
         pc2=pc_weight_total$scores[,2],
         pc3=pc_weight_total$scores[,3],
         ovr=-pc1+pc2+pc3) %>%
  select(Rank2023,PositionRank2023,FantasyPosition2023,Player2023,FantasyPointsPPR2023,pc1,pc2,pc3,ovr) %>%
  filter(FantasyPosition2023=="TE") %>%
  arrange(desc(ovr)) %>%
  tibble() 
knitr::kable(te_pctable[1:20,])

```

#### Top 75 Projected Players

```{r}
top75_table <- 
combine %>%
  mutate(pc1=pc_weight_total$scores[,1],
         pc2=pc_weight_total$scores[,2],
         pc3=pc_weight_total$scores[,3],
         overall=-pc1+pc2+pc3,
         pc2_3=pc2+pc3) %>%
  select(Rank2023,PositionRank2023,FantasyPosition2023,Player2023,FantasyPointsPPR2023,pc1,pc2,pc3,overall) %>%
 # filter(FantasyPosition2023!="QB") %>%
  arrange(desc(overall)) %>%
  tibble() 
knitr::kable(top75_table[1:75,])
```




